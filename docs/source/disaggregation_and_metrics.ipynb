{
 "metadata": {
  "name": "",
  "signature": "sha256:1c9827610b471600ca39b0bffb557e9c1e524483ead647da2d9b8b376e6018e1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Disaggregation and Metrics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nilmtk import DataSet, TimeFrame\n",
      "from nilmtk.disaggregate import CombinatorialOptimisation\n",
      "\n",
      "# Open data\n",
      "redd = DataSet('/data/REDD/redd.h5')\n",
      "\n",
      "# Select only the first half of the dataset for training\n",
      "redd.store.window = TimeFrame(start=None, end='2011-05-01 00:00:00-04:00')\n",
      "\n",
      "# Select house\n",
      "elec = redd.buildings[1].elec\n",
      "\n",
      "# Train!\n",
      "# (the co object does the appropriate preprocessing)\n",
      "# (here we are training on every appliance in the dataset; normally we \n",
      "#  would probably want to filter out appliances which don't consume much energy,\n",
      "#  see previously in the user manual for how to do this.)\n",
      "co = CombinatorialOptimisation()\n",
      "co.train(elec)\n",
      "\n",
      "print(\"Model =\", co.model)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To allow disaggregation to be done on any arbitrarily large dataset, disaggregation output is dumped to disk chunk-by-chunk:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nilmtk import HDFDataStore\n",
      "\n",
      "# Select second half of dataset for testing:\n",
      "redd.store.window = TimeFrame(start='2011-05-01 00:00:00-04:00', end=None)\n",
      "\n",
      "mains = elec.mains()\n",
      "output = HDFDataStore('output.h5', 'w')\n",
      "\n",
      "co.disaggregate(mains, output)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output.store.get('/building1/elec/meter9')[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th></th>\n",
        "      <th>power</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th></th>\n",
        "      <th>apparent</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2011-05-01 00:00:00-04:00</th>\n",
        "      <td> 87</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2011-05-01 00:01:00-04:00</th>\n",
        "      <td>  0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2011-05-01 00:02:00-04:00</th>\n",
        "      <td> 87</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2011-05-01 00:03:00-04:00</th>\n",
        "      <td>  0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2011-05-01 00:04:00-04:00</th>\n",
        "      <td>  0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2011-05-01 00:05:00-04:00</th>\n",
        "      <td> 87</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2011-05-01 00:06:00-04:00</th>\n",
        "      <td> 87</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2011-05-01 00:07:00-04:00</th>\n",
        "      <td>  0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2011-05-01 00:08:00-04:00</th>\n",
        "      <td> 87</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2011-05-01 00:09:00-04:00</th>\n",
        "      <td> 87</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "                              power\n",
        "                           apparent\n",
        "2011-05-01 00:00:00-04:00        87\n",
        "2011-05-01 00:01:00-04:00         0\n",
        "2011-05-01 00:02:00-04:00        87\n",
        "2011-05-01 00:03:00-04:00         0\n",
        "2011-05-01 00:04:00-04:00         0\n",
        "2011-05-01 00:05:00-04:00        87\n",
        "2011-05-01 00:06:00-04:00        87\n",
        "2011-05-01 00:07:00-04:00         0\n",
        "2011-05-01 00:08:00-04:00        87\n",
        "2011-05-01 00:09:00-04:00        87"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Metrics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First we load the disag output exactly as if it were a normal dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "disag = DataSet('output.h5')\n",
      "disag_elec = disag.buildings[1].elec\n",
      "\n",
      "from nilmtk.metrics import f1_score\n",
      "\n",
      "# all metrics take the same arguments:\n",
      "f1_score(disag_elec, elec)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/metrics.py:1249: UserWarning: The sum of true positives and false positives are equal to zero for some labels. Precision is ill defined for those labels [1]. The precision and recall are equal to zero for some labels. fbeta_score is ill defined for those labels [1]. \n",
        "  average=average)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/metrics.py:1249: UserWarning: The sum of true positives and false positives are equal to zero for some labels. Precision is ill defined for those labels [0]. The precision and recall are equal to zero for some labels. fbeta_score is ill defined for those labels [0]. \n",
        "  average=average)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/metrics.py:1249: UserWarning: The precision and recall are equal to zero for some labels. fbeta_score is ill defined for those labels [0]. \n",
        "  average=average)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/metrics.py:1249: UserWarning: The sum of true positives and false negatives are equal to zero for some labels. Recall is ill defined for those labels [1]. The precision and recall are equal to zero for some labels. fbeta_score is ill defined for those labels [1]. \n",
        "  average=average)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/metrics.py:1249: UserWarning: The precision and recall are equal to zero for some labels. fbeta_score is ill defined for those labels [1]. \n",
        "  average=average)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "5           0.662997\n",
        "6           0.107531\n",
        "7           0.624899\n",
        "8           0.712745\n",
        "9           0.610921\n",
        "11          0.168045\n",
        "12          0.057047\n",
        "13          0.002481\n",
        "14          0.000000\n",
        "15          0.137996\n",
        "16          0.011372\n",
        "17          0.310047\n",
        "18          0.232466\n",
        "19          0.000000\n",
        "(3, 4)      0.096890\n",
        "(10, 20)    0.162121\n",
        "dtype: float64"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "those are the F1 scores for each meter instance"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}