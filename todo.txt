* Metrics
  * Should specify preprocessing done on training data in disag
    output???  Do we need to apply same preprocessing to test data?
    I guess so.
  * TODO in combinatorial_optimisation (mostly metadata IIRC)

* Preprocessing: 
  instead of drop missing mains and make common index:
  * fill appliance gaps before doing metrics


* Stats:
  * ElecMeter.plot() and MeterGroup.plot() - how to select time? `load_kwargs`?
  * goodsectionsresults could do with a plotting function like
plot_missing_samples_with_rectangles
  * check proportion_of_energy_submetered agrees with v0.1 for REDD
  * implement energy_per_meter
  * implement dropout_rate stats node (and think about how
dropout_rate_per_period would work... supposedly we tell the loader
to load small chunks (e.g. 1 minute) and then we just need to teach
dropout_rate_results to plot like plot_missing_samples_with_bitmap.
  * implement on durations (make sure it can work with metrics)
  * activity distribution
  * building.describe() and dataset.describe()

* train_test_split (see nilmtk.cross_validation.train_test_split in v0.1)
* load only required measurements
* automatically decide size of chunk
* Do we still need Hashable?  Try making ElecMeter and Appliance
  inherit from Object.
* stats.totalenergy._energy_for_chunk looks wasteful. Why not, for
  each AC type, find cumulative energy > energy > power and then
  only run _energy_for_power_series on one column per AC type.
* FHMM (Nipun might do this)

